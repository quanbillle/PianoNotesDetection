{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 948654682340491625,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 7020285133\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 9902685878434310140\n",
       " physical_device_desc: \"device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:2d:00.0, compute capability: 7.5\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "import keras\n",
    "from tensorflow.keras import activations\n",
    "import copy\n",
    "from tensorflow.python.client import device_lib\n",
    "#tf.config.list_physical_devices(\"GPU\")\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampledir = os.path.join(os.getcwd(), \"dataset/samples\")\n",
    "sampleNotes = []\n",
    "\n",
    "for f in os.listdir(sampledir):\n",
    "    sampleNotes.append(cv2.resize(cv2.imread(os.path.join(sampledir,f\"{f}\")), (20,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\student\\miniconda3\\envs\\mlearning\\lib\\site-packages\\ipykernel_launcher.py:317: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "c:\\users\\student\\miniconda3\\envs\\mlearning\\lib\\site-packages\\ipykernel_launcher.py:322: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "c:\\users\\student\\miniconda3\\envs\\mlearning\\lib\\site-packages\\ipykernel_launcher.py:327: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    " \n",
    "train = json.load(open(os.path.join(os.getcwd(), \"dataset/Notev1/train/notev7.json\")))\n",
    "val = json.load(open(os.path.join(os.getcwd(), \"dataset/Notev1/val/notev7.json\")))\n",
    "test = json.load(open(os.path.join(os.getcwd(), \"dataset/Notev1/test/notev7.json\")))\n",
    "\n",
    "trainStaff = json.load(open(os.path.join(os.getcwd(), \"dataset/Notev1/train/StaffAndSep.json\")))\n",
    "valStaff = json.load(open(os.path.join(os.getcwd(), \"dataset/Notev1/val/StaffAndSep.json\")))\n",
    "testStaff = json.load(open(os.path.join(os.getcwd(), \"dataset/Notev1/test/StaffAndSep.json\")))\n",
    "\n",
    "\n",
    "\n",
    "def extractData(datasetStaff, datasetNotes, dirn = None):\n",
    "    mask = []\n",
    "    TotalSortedList = []\n",
    "    for data in datasetStaff:\n",
    "        annotation = [a for a in datasetStaff[data]['regions']]\n",
    "        sortedList = [i for i in range(len(annotation))]\n",
    "        for k_index, a in enumerate(sortedList): \n",
    "            index  = k_index\n",
    "            if index != len(sortedList) -1:\n",
    "                while index < len(sortedList)-1:\n",
    "                    if annotation[a]['shape_attributes']['y'] > annotation[sortedList[index+1]][\"shape_attributes\"][\"y\"]:\n",
    "                        i = sortedList[index+1]\n",
    "                        sortedList[index+1] = sortedList[index]\n",
    "                        sortedList[index] = i\n",
    "                        break\n",
    "                    index += 1\n",
    "\n",
    "            if index > 0:\n",
    "                while index > 0:\n",
    "                    if annotation[sortedList[index]]['shape_attributes']['y'] < annotation[sortedList[index-1]][\"shape_attributes\"][\"y\"]:\n",
    "                        i = sortedList[index-1]\n",
    "                        sortedList[index-1] = sortedList[index]\n",
    "                        sortedList[index] = i\n",
    "                    index -= 1\n",
    "\n",
    "        TotalSortedList.append(sortedList)\n",
    "\n",
    "\n",
    "    TrainDataset = []\n",
    "    ValDataset = []\n",
    "    c = ['G4','A4','B4','C3','D3','E3','F3','G3','A3','B3','C2','D2','E2','F2','G2','A2','B2','C','D','E','F','G']\n",
    "\n",
    "\n",
    "    for image in datasetNotes:\n",
    "        if len(datasetNotes[image]['regions']) > 0:\n",
    "            _id = ''\n",
    "            index = 0\n",
    "            for i, a in enumerate(datasetStaff):\n",
    "                if datasetNotes[image]['filename'] == datasetStaff[a]['filename']:\n",
    "                    _id  = a\n",
    "                    index = i\n",
    "                    break\n",
    "\n",
    "            img = cv2.imread(os.path.join(os.getcwd(), f\"dataset/Notev1/{dirn}/{datasetNotes[image]['filename']}\"))\n",
    "            start, end = 0, img.shape[0]\n",
    "\n",
    "            b = 0\n",
    "            while b < len(TotalSortedList[index]):\n",
    "                Height = datasetStaff[_id]['regions'][TotalSortedList[index][b]]['shape_attributes']['height']\n",
    "                if b > 0: \n",
    "                    start = datasetStaff[_id]['regions'][TotalSortedList[index][b-1]]['shape_attributes']['y']\n",
    "\n",
    "                if b + 1 < len(TotalSortedList[index]):\n",
    "                    end = datasetStaff[_id]['regions'][TotalSortedList[index][b+1]]['shape_attributes']['y']\n",
    "\n",
    "\n",
    "                \n",
    "                for note in datasetNotes[image]['regions']:\n",
    "                    load = False\n",
    "                    if note[\"region_attributes\"]['class_ids'] in c:\n",
    "                        load = True\n",
    "\n",
    "\n",
    "                    if load == True and note['shape_attributes']['y'] > start and note['shape_attributes']['y'] + note['shape_attributes']['height'] < end:\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        x = note['shape_attributes']['x']\n",
    "                        y = note['shape_attributes']['y']\n",
    "                        w = note['shape_attributes']['width']\n",
    "                        h = note['shape_attributes']['height']\n",
    "                        sh = datasetStaff[_id]['regions'][TotalSortedList[index][b]]['shape_attributes']['height']\n",
    "                        sy = datasetStaff[_id]['regions'][TotalSortedList[index][b]]['shape_attributes']['y']\n",
    "                        \n",
    "                        def distribute(data):\n",
    "                            distri = []\n",
    "\n",
    "                            av = np.average(data)\n",
    "                            for i, r in enumerate(data):\n",
    "                                distri.append(0)\n",
    "                                for c in r:\n",
    "                                    if  0.299*c[0] + 0.587*c[1] + 0.114*c[2] < av:\n",
    "\n",
    "                                        distri[i] += 1\n",
    "\n",
    "                            distri = np.array(distri)/data.shape[1]\n",
    "                            \n",
    "                            for i,v in enumerate(distri):\n",
    "                                if v > 0.9:\n",
    "                                    distri[i] = 0\n",
    "                                else:\n",
    "                                    distri[i] = 1\n",
    "                                    \n",
    "                            return distri\n",
    "                        \n",
    "                        \n",
    "                       \n",
    "                        endm = int(sy+2*Height)\n",
    "                        startm = int(sy - Height)\n",
    "                        if endm > (int(end)):\n",
    "                            endm = int(end)\n",
    "                        \n",
    "                        if startm < start:\n",
    "                            startm = start\n",
    "                            \n",
    "                        topmost = sy-startm\n",
    "                        bottommost = y+h - startm\n",
    "                        \n",
    "                        if y-startm < topmost:\n",
    "                            topmost = y - startm\n",
    "                        \n",
    "                        if bottommost < sy + sh -startm:\n",
    "                            bottommost = sy + sh - startm\n",
    "                        \n",
    "                        \n",
    "                        #mask = np.zeros((3*sh,w,6))\n",
    "                            \n",
    "                        mask = []\n",
    "                        cmask =  copy.deepcopy(img[startm:endm,x:x+w,:])\n",
    "                        staffFilter = distribute(img[sy:sy+sh,x:x+w,:])\n",
    "            \n",
    "                        \n",
    "                        bmask = np.zeros((cmask.shape[0],cmask.shape[1],3)) + 255\n",
    "                        bmask[sy-startm: sy+sh-startm,:,:] = 0\n",
    "                        #mask.append(img[startm:endm,x:x+w,:])\n",
    "                        \n",
    "                        background = np.average(img[startm:endm,x:x+w,:]) + 255\n",
    "                        background /= 2\n",
    "                        \n",
    "                        cmask[0:sy-startm,:,:] = background\n",
    "                        cmask[sy+sh-startm: cmask.shape[0], :,:] = background\n",
    "                        \n",
    "                        bmask = copy.deepcopy(cmask)\n",
    "                        \n",
    "                        gooddata = True\n",
    "                        \n",
    "                        notem = np.zeros((h, w,3))\n",
    "                        hrw = h/w\n",
    "                        for nr in range(h):\n",
    "                            for nc in range(w):\n",
    "                                if (nr - h/2)**2 + (hrw)**2*(nc - w/2)**2 < h**2/4:\n",
    "                                    notem[nr, nc,:] = 1\n",
    "                                    \n",
    "                        try:\n",
    "                        \n",
    "                            for mr, rv in enumerate(notem):\n",
    "                                for mc,cv in enumerate(rv):\n",
    "                                    if cv[0]== 0:\n",
    "                                        cmask[y-startm+mr, mc,:] = 255\n",
    "                                    else:\n",
    "                                        cmask[y-startm+mr, mc,:] = copy.deepcopy(img[y+mr,x+mc,:])\n",
    "                        except:\n",
    "                            gooddata = False\n",
    "                            pass\n",
    "                        #print(h)\n",
    "                        \n",
    "                        #cmask[y - startm: y+h - startm,:,:] = copy.deepcopy(notem)\n",
    "                        #print(h)\n",
    "                                    \n",
    "                                    \n",
    "                        \n",
    "                                \n",
    "                                    \n",
    "                            \n",
    "                        #cmask = cv2.resize(cmask, (20,100))\n",
    "                        #bmask = cv2.resize(bmask, (20,100))\n",
    "                        \n",
    "                        def finetuneImage(data, fil):\n",
    "                            data = np.array(data)\n",
    "                            fil = np.array(fil)\n",
    "                            for i, v in enumerate(data):\n",
    "                                for j,a in enumerate(v):\n",
    "                                    data[i,j,0] *= fil[i]\n",
    "                                    data[i,j,1] *= fil[i]\n",
    "                                    data[i,j,2] *= fil[i]\n",
    "                            \n",
    "                            return data\n",
    "                        \n",
    "                        cmask[sy-startm: sy+sh-startm,:,:] = finetuneImage(cmask[sy-startm: sy+sh-startm,:,:], staffFilter)\n",
    "                        \n",
    "                        def distribute(data):\n",
    "                            distri = []\n",
    "                            av = np.average(data)\n",
    "                            for i, r in enumerate(data):\n",
    "                                distri.append(0)\n",
    "                                for c in r:\n",
    "                                    if  0.299*c[0] + 0.587*c[1] + 0.114*c[2] < av:\n",
    "\n",
    "                                        distri[i] += 1\n",
    "                                        \n",
    "                            distri = np.array(distri)/data.shape[1]\n",
    "                            \n",
    "                            #pos = [1,0]\n",
    "\n",
    "                            #for i,v in enumerate(distri):\n",
    "                            #    if v > 0.8:\n",
    "                            #        pos[0] = i\n",
    "                            #        break\n",
    "                            \n",
    "                            #for i in range(len(distri)):\n",
    "                            #    if distri[len(distri) - i-1] == 1:\n",
    "                            #        pos[1]= len(distri) - i-1\n",
    "                            #        break\n",
    "\n",
    "                            return distri\n",
    "                        \n",
    "                        spos = distribute(cmask)\n",
    "                        subsh = sh/4\n",
    "                        rjk = spos\n",
    "                        \n",
    "                        \n",
    "                        mask.append(cmask)\n",
    "                        mask.append(copy.deepcopy(img[startm:endm,x:x+w,:]))\n",
    "                      \n",
    "                        \n",
    "            \n",
    "                        \n",
    "                        \n",
    "                        if gooddata == True:\n",
    "                            TrainDataset.append({'mask': [cv2.resize(cmask, (20,100)),rjk], \"class_ids\": note[\"region_attributes\"]['class_ids']})\n",
    "                            \n",
    "                            if dirn == 'train':\n",
    "                                down = 5\n",
    "                                while bottommost + down < mask[0].shape[0]:\n",
    "                                    temcm = np.zeros(mask[0].shape) + 255\n",
    "                                    temcm[topmost+down: bottommost+down,:,:] = copy.deepcopy(mask[0][topmost:bottommost,:,:])\n",
    "                                    tembm = np.zeros(mask[1].shape) + 255\n",
    "                                    tembm[topmost+down: bottommost+down,:,:] = copy.deepcopy(mask[1][topmost:bottommost,:,:])\n",
    "                                    down += 5\n",
    "                                    TrainDataset.append({'mask': [cv2.resize(temcm, (20,100)), rjk], \"class_ids\": note[\"region_attributes\"]['class_ids']})\n",
    "                                    expandDim = np.zeros((6,temcm.shape[1],3)) + 255\n",
    "                                    #for k in range(10):\n",
    "                                    #    temcm = np.concatenate((temcm,expandDim))\n",
    "                                    #    TrainDataset.append({'mask': [cv2.resize(temcm, (20,100)), rjk], \"class_ids\": note[\"region_attributes\"]['class_ids']})\n",
    "                                    \n",
    "                                down = 5\n",
    "                                while topmost-down > 0:\n",
    "                                    temcm = np.zeros(mask[0].shape) + 255\n",
    "                                    temcm[topmost-down: bottommost-down,:,:] = copy.deepcopy(mask[0][topmost:bottommost,:,:])\n",
    "                                    tembm = np.zeros(mask[1].shape) + 255\n",
    "                                    tembm[topmost-down: bottommost-down,:,:] = copy.deepcopy(mask[1][topmost:bottommost,:,:])\n",
    "                                    down += 5\n",
    "                                    TrainDataset.append({'mask': [cv2.resize(temcm, (20,100)),rjk], \"class_ids\": note[\"region_attributes\"]['class_ids']})\n",
    "                                    expandDim = np.zeros((6,temcm.shape[1],3)) + 255\n",
    "                                    #for k in range(10):\n",
    "                                    #    temcm = np.concatenate((expandDim, temcm))\n",
    "                                    #    TrainDataset.append({'mask': [cv2.resize(temcm, (20,100)), rjk], \"class_ids\": note[\"region_attributes\"]['class_ids']})\n",
    "                                \n",
    "                            \n",
    "                            \n",
    "\n",
    "\n",
    "\n",
    "                b += 2    \n",
    "    dict_c = {}\n",
    "    for i, _class in enumerate(c):\n",
    "        dict_c[_class] = i\n",
    "\n",
    "\n",
    "    TotalMask = [[] for i in range(len(c))]\n",
    " \n",
    "    \n",
    "\n",
    "    \n",
    "    for i in TrainDataset:\n",
    "        TotalMask[dict_c[i['class_ids']]].append(i['mask'])\n",
    "    \n",
    "    return TotalMask\n",
    "\n",
    "train_dataset = extractData(trainStaff,train, 'train')\n",
    "val_dataset = extractData(valStaff, val, 'val')\n",
    "test_dataset = extractData(testStaff, test, 'test')\n",
    "\n",
    "testM_x = []\n",
    "\n",
    "test_y = []\n",
    "\n",
    "trainM_x = []\n",
    "\n",
    "train_y = []\n",
    "\n",
    "valM_x = []\n",
    "\n",
    "val_y = []\n",
    "\n",
    "for i,data in enumerate(train_dataset):\n",
    "    for k, info in enumerate(data):\n",
    "        trainM_x.append(info)\n",
    "        \n",
    "        train_y.append(i)\n",
    "        \n",
    "for i,data in enumerate(val_dataset):\n",
    "    for k, info in enumerate(data):\n",
    "        valM_x.append(info)\n",
    "        \n",
    "        val_y.append(i)\n",
    "        \n",
    "for i,data in enumerate(test_dataset):\n",
    "    for k, info in enumerate(data):\n",
    "        testM_x.append(info)\n",
    "       \n",
    "        test_y.append(i)\n",
    "        \n",
    "\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "trainM_x = np.array(trainM_x)\n",
    "\n",
    "\n",
    "val_y = np.array(val_y)\n",
    "\n",
    "valM_x = np.array(valM_x)\n",
    "\n",
    "\n",
    "test_y = np.array(test_y)\n",
    "  \n",
    "testM_x = np.array(testM_x)\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_img(data):\n",
    "    finalized_data = []\n",
    "    for y in range(10):\n",
    "        for i in range(2):\n",
    "            finalized_data.append(data[20*y: 20*(y+1), 25*i: 25*(i+1),:])\n",
    "    return np.array(finalized_data)\n",
    "#print(np.array(sampleNotes).shape)\n",
    "\n",
    "def extract_infor(dataset):\n",
    "    image1 = []\n",
    "    image2 = []\n",
    "    for i, v in enumerate(dataset):\n",
    "        image1.append(np.rot90(v[0]))\n",
    "        image2.append(v[0])\n",
    "        \n",
    "    \n",
    "    return np.array(image1)/255, np.array(image2)/255\n",
    "\n",
    "trainM1_x, trainM2_x = extract_infor(trainM_x)\n",
    "testM1_x, testM2_x = extract_infor(testM_x)\n",
    "valM1_x, valM2_x = extract_infor(valM_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute(datas):\n",
    "    allDis = []\n",
    "    for data in datas:\n",
    "        distri = [] \n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        av = np.average(data)\n",
    "        for i in range(data.shape[1]):\n",
    "            distri.append([0,0,0])\n",
    "            for c in data[:,i,:]:\n",
    "                if  0.299*c[0] + 0.587*c[1] + 0.114*c[2] > av:\n",
    "\n",
    "                    distri[i][0]+= 1\n",
    "                    distri[i][1]+= 1\n",
    "                    distri[i][2]+= 1\n",
    "                   \n",
    "        \n",
    "        distri = np.array(distri)/20\n",
    "        \n",
    "        allDis.append(distri)\n",
    "    \n",
    "    \n",
    "    return np.array(allDis)\n",
    "\n",
    "trainM2_x = distribute(trainM1_x)\n",
    "testM2_x = distribute(testM1_x)\n",
    "valM2_x = distribute(valM1_x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3583, 100, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2004e773d68>,\n",
       " <matplotlib.lines.Line2D at 0x20054d0a860>,\n",
       " <matplotlib.lines.Line2D at 0x20054d0a978>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (10,7))\n",
    "\n",
    "j = 2000\n",
    "\n",
    "#fig.add_subplot(2, 2, 1)\n",
    "#plt.imshow(trainM2_x[j])\n",
    "print(trainM2_x.shape)\n",
    "fig.add_subplot(2, 2, 1)\n",
    "x = [i for i in range(len(trainM2_x[j]))]\n",
    "plt.plot(x, trainM2_x[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\student\\miniconda3\\envs\\mlearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20000378e80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class noteFocustest(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(noteFocustest, self).__init__()\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.space = np.zeros((100,3))\n",
    "        for i in range(self.space.shape[0]):\n",
    "            self.space[i][0] = i + 50\n",
    "            self.space[i][1] = i + 50\n",
    "            self.space[i][2] = i +50\n",
    "        self.space = self.space/150\n",
    "        self.space = tf.convert_to_tensor(self.space, dtype = tf.float64)\n",
    "        \n",
    "        \n",
    "    def get_w(self):\n",
    "        return self.space\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        r = tf.math.multiply(self.space, inputs)\n",
    "        r = tf.cast(r, dtype = tf.float32)\n",
    "        return r\n",
    "\n",
    "nf = noteFocustest()\n",
    "nf.build(3)\n",
    "\n",
    "b = nf.call(tf.convert_to_tensor(trainM1_x[0]))\n",
    "b = b.eval(session = tf.Session())\n",
    "plt.imshow(np.multiply(b, trainM2_x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class noteFocus(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(noteFocus, self).__init__()\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.space = np.zeros((100,3))\n",
    "        for i in range(self.space.shape[0]):\n",
    "            self.space[i][0] = i - 0\n",
    "            self.space[i][1] = i - 0\n",
    "            self.space[i][2] = i - 0\n",
    "        self.space = self.space/100\n",
    "        self.space = tf.convert_to_tensor(self.space, dtype = tf.float64)\n",
    "        \n",
    "        \n",
    "    def get_w(self):\n",
    "        return self.space\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        r = tf.math.multiply(self.space, tf.cast(inputs, dtype = tf.float64))\n",
    "        r = tf.math.subtract(tf.cast(inputs, dtype = tf.float64), r)\n",
    "        r = tf.cast(r, dtype = tf.float32)\n",
    "        return r\n",
    "\n",
    "class noteDistri(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(noteDistri, self).__init__()\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.x = tf.placeholder_with_default(tf.convert_to_tensor(np.zeros((20,100,3)), dtype = tf.float64), shape = [20,100,3]) \n",
    "        \n",
    "    def get_input(self, data):\n",
    "        distri = []\n",
    "        av = np.average(data)\n",
    "        for i in range(data.shape[1]):\n",
    "            distri.append([0,0,0])\n",
    "            for c in data[:,i,:]:\n",
    "                if  0.299*c[0] + 0.587*c[1] + 0.114*c[2] > av:\n",
    "\n",
    "                    distri[i][0]+= 1\n",
    "                    distri[i][1]+= 1\n",
    "                    distri[i][2]+= 1\n",
    "                   \n",
    "        \n",
    "        distri = np.array(distri)/20\n",
    "        \n",
    "        \n",
    "        return distri\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        mean = tf.math.reduce_mean(inputs)\n",
    "        k = tf.where(inputs < mean)\n",
    "        print(k)\n",
    "        return k\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv = noteDistri()\n",
    "nb = noteFocus()\n",
    "nb.build(3)\n",
    "bv.build(3)\n",
    "\n",
    "\n",
    "bv = bv.call(tf.convert_to_tensor(trainM1_x[1200]))\n",
    "nb = nb.call(bv)\n",
    "\n",
    "nb = tf.math.multiply(tf.convert_to_tensor(trainM1_x[1200], dtype = tf.float32), nb)\n",
    "\n",
    "#nb = nb.eval(session = tf.Session())\n",
    "fig = plt.figure(figsize = (10,7))\n",
    "\n",
    "j = 1200\n",
    "\n",
    "fig.add_subplot(2, 2, 1)\n",
    "#plt.imshow(nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import layers\n",
    "c = ['G4','A4','B4','C3','D3','E3','F3','G3','A3','B3','C2','D2','E2','F2','G2','A2','B2','C','D','E','F','G']\n",
    "\n",
    "class noteFocus(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(noteFocus, self).__init__()\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.space = np.zeros((100,3))\n",
    "        for i in range(self.space.shape[0]):\n",
    "            self.space[i][0] = i + 50\n",
    "            self.space[i][1] = i + 50\n",
    "            self.space[i][2] = i +50\n",
    "        self.space = self.space/150\n",
    "        self.space = tf.convert_to_tensor(self.space, dtype = tf.float32)\n",
    "        \n",
    "        \n",
    "    def get_w(self):\n",
    "        return self.space\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        r = tf.math.multiply(self.space, inputs)\n",
    "        r = tf.cast(r, dtype = tf.float32)\n",
    "        return r\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def conv_block(size, strike, input_tensor):\n",
    "    x = keras.layers.Conv2D(size,strike, padding = \"same\")(input_tensor)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation(activations.relu)(x)\n",
    "    x = keras.layers.Conv2D(size,strike, padding = \"same\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation(activations.relu)(x)\n",
    "    x = keras.layers.Conv2D(size,strike, padding = \"same\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation(activations.relu)(x)\n",
    "    \n",
    "    shotcut = keras.layers.Conv2D(size,strike, padding = \"same\")(input_tensor)\n",
    "    shotcut = keras.layers.Activation(activations.relu)(shotcut)\n",
    "\n",
    "    x = keras.layers.Add()([x, shotcut])\n",
    "    x = keras.layers.Activation(activations.relu)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def identity_block(size, strike, input_tensor):\n",
    "    x = keras.layers.Conv2D(size,strike, padding = \"same\")(input_tensor)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation(activations.relu)(x)\n",
    "    x = keras.layers.Conv2D(size,strike, padding = \"same\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation(activations.relu)(x)\n",
    "    x = keras.layers.Conv2D(size,strike, padding = \"same\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation(activations.relu)(x)\n",
    "\n",
    "    x = keras.layers.Add()([x, input_tensor])\n",
    "    x = keras.layers.Activation(activations.relu)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "#inputs = keras.layers.Input(shape = [100,20,3])\n",
    "\n",
    "input_tensor = keras.layers.Input(shape = [20,100,3], name = \"input\")\n",
    "distri_tensor = keras.layers.Input(shape = [100,3])\n",
    "\n",
    "\n",
    "#distri_tensor = noteDistri()(input_tensor)\n",
    "o = noteFocus()(distri_tensor)\n",
    "#reshape = keras.layers.Reshape((20,100,3))(input_tensor)\n",
    "#x = noteFocus()(input_tensor)\n",
    "x = keras.layers.Multiply()([o, input_tensor])\n",
    "\n",
    "x = conv_block(64,1,x)\n",
    "x = identity_block(64,1,x)\n",
    "\n",
    "x = conv_block(64,3,x)\n",
    "x = identity_block(64,3,x)\n",
    "x = identity_block(64,3,x)\n",
    "x = identity_block(64,3,x)\n",
    "x = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "\n",
    "x = conv_block(128,3,x)\n",
    "x = identity_block(128,3,x)\n",
    "x = identity_block(128,3,x)\n",
    "x = identity_block(128,3,x)\n",
    "x = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "\n",
    "x = conv_block(256,3,x)\n",
    "x = identity_block(256,3,x)\n",
    "x = identity_block(256,3,x)\n",
    "x = identity_block(256,3,x)\n",
    "x = identity_block(256,3,x)\n",
    "x = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "x = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "x = conv_block(512,3,x)\n",
    "x = identity_block(512,3,x)\n",
    "x = identity_block(512,3,x)\n",
    "x = identity_block(512,3,x)\n",
    "x = identity_block(512,3,x)\n",
    "x = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "x = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "\n",
    "x = keras.layers.Flatten()(x)\n",
    "#o = keras.layers.Flatten()(distri_tensor)\n",
    "#o = keras.layers.Dense(4096)(o)\n",
    "a = keras.layers.Dense(4096, activation = 'relu')(x)\n",
    "#a = keras.layers.Multiply()([o,a])\n",
    "\n",
    "a = keras.layers.Dense(2048, activation = 'relu')(a)\n",
    "\n",
    "a = keras.layers.Dense(1024, activation = 'relu')(a)\n",
    "a = keras.layers.Dense(512, activation = 'relu')(a)\n",
    "a = keras.layers.Dense(256, activation = 'relu')(a)\n",
    "a = keras.layers.Dense(128, activation = 'relu')(a)\n",
    "a = keras.layers.Dense(96, activation = 'relu')(a)      \n",
    "a = keras.layers.Dense(48, activation = 'relu')(a)  \n",
    "output = keras.layers.Dense(len(c), activation = \"softmax\")(a)\n",
    "\n",
    "\n",
    "model  = keras.Model(inputs = [input_tensor, distri_tensor], outputs = [output])\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='sgd', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#aug = ImageDataGenerator(zoom_range=0.2,vertical_flip=True)\n",
    "aug = ImageDataGenerator()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_img(x, y):\n",
    "    xob = []\n",
    "    for a in x:\n",
    "        xob.append(aug.flow(a, y,seed=1))\n",
    "        \n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        xc = []\n",
    "        for a in xob:\n",
    "            xc.append(a.next())\n",
    "        yield [b[0] for b in xc], xc[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr = 0.001, momentum = 0.9, decay=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2428/3583 [===================>..........] - ETA: 7:45 - loss: 0.6100 - acc: 0.8138"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "with tf.device('/CPU:0'):\n",
    "    his = model.fit_generator(aug.flow([trainM1_x, trainM2_x], train_y), epochs = 5, steps_per_epoch =len(trainM2_x) , validation_steps = 300, validation_data=([valM1_x, valM2_x], val_y), shuffle=True, workers= multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"NoteClassificationv2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "with tf.device('/CPU:0'):\n",
    "    his = model.fit_generator(aug.flow([trainM1_x, trainM2_x], train_y), epochs = 10, steps_per_epoch =len(trainM2_x) , validation_steps = 200, validation_data=([valM1_x, valM2_x], val_y), shuffle=True, workers= multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr = 0.001, momentum = 0.9, decay=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 8, 9, 9, 10, 11, 11]\n"
     ]
    }
   ],
   "source": [
    "prey = model.predict([testM1_x, testM2_x])\n",
    "\n",
    "\n",
    "maxv = []\n",
    "\n",
    "for ipred in range(len(prey)):\n",
    "    \n",
    "    maxs = 0\n",
    "    for i,index in enumerate(prey[ipred]):\n",
    "        if index > prey[ipred][maxs]:\n",
    "            maxs = i\n",
    "\n",
    "    maxv.append(maxs)\n",
    "\n",
    "print(maxv)\n",
    "c = ['G4','A4','B4','C3','D3','E3','F3','G3','A3','B3','C2','D2','E2','F2','G2','A2','B2','C','D','E','F','G']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,7))\n",
    "#fig.add_subplot(2,2,1)\n",
    "#plt.imshow(testM1_x[5])\n",
    "\n",
    "fig.add_subplot(2,2,2)\n",
    "plt.imshow(testM1_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"NoteClassificationv3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras import activations\n",
    "c = ['G4','A4','B4','C3','D3','E3','F3','G3','A3','B3','C2','D2','E2','F2','G2','A2','B2','C','D','E','F','G']\n",
    "\n",
    "#GOOD - input: rate, height\n",
    "input_A = keras.layers.Input(shape = [100,20,3], name = 'noteMask')\n",
    "#input_B = keras.layers.Input(shape = [100], name = 'staffMask')\n",
    "#input_B = keras.layers.Input(shape = [1], name = \"dis\")\n",
    "#input_C = keras.layers.Input(shape = [1], name = \"staffHeihgt\")\n",
    "\n",
    "\"\"\"\n",
    "conv1 = keras.layers.Conv2D(64,1, padding = \"same\")(input_A)\n",
    "conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "conv1 = keras.layers.Activation(activations.relu)(conv1)\n",
    "conv1 = keras.layers.Conv2D(64,1, padding = \"same\")(conv1)\n",
    "conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "conv1 = keras.layers.Activation(activations.relu)(conv1)\n",
    "conv1 = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "conv1 = keras.layers.Conv2D(64,1, padding = \"same\")(conv1)\n",
    "conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "conv1 = keras.layers.Activation(activations.relu)(conv1)\n",
    "conv1 = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "conv1 = keras.layers.Conv2D(64,1, padding = \"same\")(conv1)\n",
    "conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "conv1 = keras.layers.Activation(activations.relu)(conv1)\n",
    "conv1 = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\"\"\"\n",
    "hidden_A = input_A\n",
    "for u in range(2):\n",
    "    initLayer = keras.layers.Conv2D(64,1, padding = \"same\")(hidden_A)      \n",
    "    conv1 = keras.layers.BatchNormalization()(initLayer)\n",
    "    conv1 = keras.layers.Activation(activations.relu)(conv1)\n",
    "    conv1 = keras.layers.Conv2D(64,1, padding = \"same\")(conv1)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.Activation(activations.relu)(conv1)\n",
    "    hidden_A = keras.layers.Add()([conv1, initLayer])\n",
    "    \n",
    "originalInput = keras.layers.Conv2D(64,1, padding = \"same\")(input_A)\n",
    "originalInput = keras.layers.BatchNormalization()(originalInput)\n",
    "originalInput = keras.layers.Activation(activations.relu)(originalInput)\n",
    "hidden_A = keras.layers.Add()([hidden_A,originalInput])\n",
    "\n",
    "hidden_A = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(hidden_A)\n",
    "\n",
    "for u in range(2):\n",
    "    initLayer = keras.layers.Conv2D(64,3, padding = \"same\")(hidden_A)      \n",
    "    conv1 = keras.layers.BatchNormalization()(initLayer)\n",
    "    conv1 = keras.layers.Activation(activations.relu)(conv1)\n",
    "    conv1 = keras.layers.Conv2D(64,3, padding = \"same\")(conv1)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.Activation(activations.relu)(conv1)\n",
    "    hidden_A = keras.layers.Add()([conv1, initLayer])\n",
    "\n",
    "originalInput = keras.layers.Conv2D(64,3, padding = \"same\")(input_A)\n",
    "originalInput = keras.layers.BatchNormalization()(originalInput)\n",
    "originalInput = keras.layers.Activation(activations.relu)(originalInput)\n",
    "hidden_A = keras.layers.Add()([hidden_A,originalInput])\n",
    "\n",
    "hidden_A = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(hidden_A)\n",
    "\n",
    "for u in range(2):\n",
    "    initLayer = keras.layers.Conv2D(128,3, padding = \"same\")(hidden_A)      \n",
    "    conv1 = keras.layers.BatchNormalization()(initLayer)\n",
    "    conv1 = keras.layers.Activation(activations.relu)(conv1)\n",
    "    conv1 = keras.layers.Conv2D(128,3, padding = \"same\")(conv1)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.Activation(activations.relu)(conv1)\n",
    "    hidden_A = keras.layers.Add()([conv1, initLayer])\n",
    "    \n",
    "originalInput = keras.layers.Conv2D(128,3, padding = \"same\")(input_A)\n",
    "originalInput = keras.layers.BatchNormalization()(originalInput)\n",
    "originalInput = keras.layers.Activation(activations.relu)(originalInput)\n",
    "hidden_A = keras.layers.Add()([hidden_A,originalInput])\n",
    "\n",
    "hidden_A = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(hidden_A)\n",
    "\n",
    "for u in range(2):\n",
    "    initLayer = keras.layers.Conv2D(256,3, padding = \"same\")(hidden_A)      \n",
    "    conv1 = keras.layers.BatchNormalization()(initLayer)\n",
    "    #conv1 = keras.layers.Activation(activations.relu)(conv1)\n",
    "    conv1 = keras.layers.Conv2D(256,3, padding = \"same\")(conv1)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    #conv1 = keras.layers.Activation(activations.relu)(conv1)\n",
    "    hidden_A = keras.layers.Add()([conv1, initLayer])\n",
    "\n",
    "originalInput = keras.layers.Conv2D(256,3, padding = \"same\")(input_A)\n",
    "originalInput = keras.layers.BatchNormalization()(originalInput)\n",
    "originalInput = keras.layers.Activation(activations.relu)(originalInput)\n",
    "hidden_A = keras.layers.Add()([hidden_A,originalInput])    \n",
    "\n",
    "hidden_A = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(hidden_A)\n",
    "\n",
    "\n",
    "for u in range(2):\n",
    "    initLayer = keras.layers.Conv2D(512,3, padding = \"same\")(hidden_A)      \n",
    "    conv1 = keras.layers.BatchNormalization()(initLayer)\n",
    "    #conv1 = keras.layers.Activation(activations.relu)(conv1)\n",
    "    conv1 = keras.layers.Conv2D(512,3, padding = \"same\")(conv1)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    #conv1 = keras.layers.Activation(activations.relu)(conv1)\n",
    "    hidden_A = keras.layers.Add()([conv1, initLayer])\n",
    "\n",
    "originalInput = keras.layers.Conv2D(512,3, padding = \"same\")(input_A)\n",
    "originalInput = keras.layers.BatchNormalization()(originalInput)\n",
    "originalInput = keras.layers.Activation(activations.relu)(originalInput)\n",
    "hidden_A = keras.layers.Add()([hidden_A,originalInput])  \n",
    "\n",
    "\n",
    "#hidden_3 = keras.layers.Conv2D(128,3, padding = \"same\")(conv1)\n",
    "#conv1 = keras.layers.BatchNormalization()(hidden_3)\n",
    "conv1 = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(hidden_A)\n",
    "\n",
    "#conv1 = keras.layers.Flatten()(conv1)\n",
    "\n",
    "#conv1 = keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same')(conv1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hidden_A = keras.layers.Flatten()(conv1)\n",
    "\n",
    "#hidden_A = keras.layers.Dense(4096, activation = \"relu\")(hidden_A)\n",
    "#hidden_B = keras.layers.Dense(4096, activation = 'relu')(input_B)\n",
    "#hidden_A = keras.layers.Multiply()([hidden_A,hidden_B])\n",
    "\n",
    "hidden_A = keras.layers.Dense(2048, activation = \"relu\")(hidden_A)\n",
    "#hidden_B = keras.layers.Dense(2048, activation = 'relu')(input_B)\n",
    "#hidden_A = keras.layers.Multiply()([hidden_A,hidden_B])\n",
    "\n",
    "hidden_A = keras.layers.Dense(1024, activation = \"relu\")(hidden_A)\n",
    "#hidden_B = keras.layers.Dense(1024, activation = 'relu')(input_B)\n",
    "#hidden_A = keras.layers.Multiply()([hidden_A,hidden_B])\n",
    "#concat = keras.layers.BatchNormalization()(concat)\n",
    "hidden_A = keras.layers.Dense(512, activation=\"relu\")(hidden_A)\n",
    "#hidden_B = keras.layers.Dense(512, activation=\"relu\")(input_B)\n",
    "#hidden_A = keras.layers.Multiply()([hidden_A,hidden_B])\n",
    "#concat = keras.layers.BatchNormalization()(concat)\n",
    "hidden_A = keras.layers.Dense(256, activation=\"relu\")(hidden_A)\n",
    "#hidden_B = keras.layers.Dense(256, activation=\"relu\")(input_B)\n",
    "#hidden_A = keras.layers.Multiply()([hidden_A,hidden_B])\n",
    "#concat = keras.layers.BatchNormalization()(concat)\n",
    "hidden_A = keras.layers.Dense(128, activation=\"relu\")(hidden_A)\n",
    "#hidden_B = keras.layers.Dense(128, activation=\"relu\")(input_B)\n",
    "#hidden_A = keras.layers.Multiply()([hidden_A,hidden_B])\n",
    "#concat = keras.layers.BatchNormalization()(concat)\n",
    "hidden_A = keras.layers.Dense(64, activation=\"relu\")(hidden_A)\n",
    "#hidden_B = keras.layers.Dense(64, activation=\"relu\")(input_B)\n",
    "#hidden_A = keras.layers.Multiply()([hidden_A,hidden_B])\n",
    "hidden_A = keras.layers.Dense(32, activation=\"relu\")(hidden_A)\n",
    "    \n",
    "        \n",
    "output = keras.layers.Dense(len(c), activation = \"softmax\")(hidden_A)\n",
    "\n",
    "#hidden_B1 = keras.layers.Dense(128, activation = \"relu\")(input_B)\n",
    "#hidden_B2 = keras.layers.Dense(96, activation = \"relu\")(hidden_B1)\n",
    "#final_B = keras.layers.Dense(len(c), activation = \"softmax\")(flatten)\n",
    "\n",
    "#concat = keras.layers.concatenate([final_A, final_B])\n",
    "#output = keras.layers.Dense(len(c),name = \"output\", activation = \"softmax\")(concat)\n",
    "\n",
    "model  = keras.Model(inputs = [input_A], outputs = [output])\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "model = keras.models.Sequential()\n",
    "#model.add(keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\", input_shape = [100,1,3]))\n",
    "#model.add(keras.layers.MaxPooling2D(1))\n",
    "model.add(keras.layers.Dense(1, input_shape=[100,1,3]))\n",
    "model.add(keras.layers.Flatten())\n",
    "#model.add(keras.layers.Dense(512, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(256, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(128, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(128, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(96, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(len(c), activation = 'softmax'))\n",
    "\"\"\"\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr = 0.001, momentum = 0.9, decay=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='sgd', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
